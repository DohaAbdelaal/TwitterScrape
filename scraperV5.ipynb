{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ntscraper\n",
      "  Downloading ntscraper-0.3.13-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ntscraper) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ntscraper) (4.12.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ntscraper) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->ntscraper) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->ntscraper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->ntscraper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->ntscraper) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\doha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->ntscraper) (2023.11.17)\n",
      "Downloading ntscraper-0.3.13-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: ntscraper\n",
      "Successfully installed ntscraper-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install importatnt packages\n",
    "pip install ntscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Nitter for twitter scrapping\n",
    "from ntscraper import Nitter \n",
    "#import time to calculate scraping session time and interval between 2 sessions\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 77/77 [02:10<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "#create Nitter instance\n",
    "# Specify the logging level for Nitter (1 means INFO level)\n",
    "# Determine whether to skip checking if Nitter is already running\n",
    "scraper=Nitter(log_level=1, skip_instance_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of tweets scraper will use to search through\n",
    "Number_of_tweets=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get total the number of occurnces of the required word in all of the accounts\n",
    "def count_occurrence(accounts, Required_word):   \n",
    "    #initialize the occurnce counter with zero\n",
    "    Occurence=0 \n",
    "    # Loop through each account in the accounts list\n",
    "    for account in accounts:\n",
    "        # Get tweets for the current account using the scraper\n",
    "        tweets=scraper.get_tweets(account,mode=\"user\",number=Number_of_tweets)\n",
    "        # Extract the list of tweets from the response\n",
    "        tweet_list = tweets['tweets']\n",
    "        tweet_count = len(tweet_list) # Count the number of tweets\n",
    "        \n",
    "        # Loop through each tweet in the tweet list\n",
    "        for i in range(tweet_count):\n",
    "            # Get the text of the current tweet\n",
    "            tweet_text=tweets['tweets'][i]['text']\n",
    "            # Count the occurrences of the Required_word in the tweet\n",
    "            count_per_tweet=tweet_text.count(Required_word)\n",
    "            # Update the total Occurrence count\n",
    "            Occurence=Occurence+count_per_tweet\n",
    "        # Pause execution for 15 seconds before processing the next account    \n",
    "        time.sleep(15)\n",
    "    return  Occurence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_result(accounts, Required_word):\n",
    "    # Start the timer\n",
    "    start_time = time.time() # Record the start time\n",
    "    \n",
    "    # Call the count_occurrence function to count occurrences of the Required_word\n",
    "    Occurence=count_occurrence(accounts, Required_word)\n",
    "    end_time = time.time()   # Record the end time\n",
    "\n",
    "    # Calculate the elapsed time in seconds and convert to minutes\n",
    "    elapsed_time = end_time - start_time\n",
    "    # Convert elapsed time from seconds to minutes\n",
    "    elapsed_minutes = elapsed_time / 60\n",
    "    \n",
    "    # Return the total Occurrence count and the elapsed time in minutes\n",
    "    return Occurence,elapsed_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(accounts, stock_symbol, interval):\n",
    "    \"\"\"\n",
    "    Main function to repeatedly scrape Twitter accounts at a specified interval.\n",
    "\n",
    "    Args:\n",
    "    usernames (list): List of Twitter account usernames.\n",
    "    stock_symbol (str): The stock symbol to look for (e.g., $AAPL).\n",
    "    interval (int): The time interval (in minutes) between scrapes.\n",
    "    \"\"\"\n",
    "    while True: # Keep looping indefinitely\n",
    "        # Call the scraping_result function to get occurrence count and elapsed time\n",
    "        occurrence,elapsed_minutes=scraping_result(accounts, stock_symbol)\n",
    "        \n",
    "        # Print scraping results\n",
    "        print(f\"{stock_symbol} was mentioned {occurrence} times in the last {elapsed_minutes:.2f} minutes\")\n",
    "        \n",
    "        # Wait for the specified interval before next scraping session\n",
    "        time.sleep(interval * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-May-24 23:55:44 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:55:52 - Current stats for Mr_Derivatives: 10 tweets, 0 threads...\n",
      "27-May-24 23:56:07 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:56:13 - Current stats for warrior_0719: 10 tweets, 0 threads...\n",
      "27-May-24 23:56:28 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:56:33 - Current stats for ChartingProdigy: 10 tweets, 0 threads...\n",
      "27-May-24 23:56:48 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:56:54 - Current stats for allstarcharts: 10 tweets, 0 threads...\n",
      "27-May-24 23:57:09 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:57:09 - Empty page on https://nitter.privacydev.net\n",
      "27-May-24 23:57:26 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:57:27 - Empty page on https://nitter.privacydev.net\n",
      "27-May-24 23:57:44 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:57:50 - Current stats for AdamMancini4: 10 tweets, 0 threads...\n",
      "27-May-24 23:58:05 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:58:06 - Empty page on https://nitter.privacydev.net\n",
      "27-May-24 23:58:23 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:58:24 - Empty page on https://nitter.privacydev.net\n",
      "27-May-24 23:58:41 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "27-May-24 23:58:42 - Empty page on https://nitter.privacydev.net\n",
      "$AAPL was mentioned 2 times in the last 3.25 minutes\n",
      "28-May-24 00:03:59 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:04:04 - Current stats for Mr_Derivatives: 10 tweets, 0 threads...\n",
      "28-May-24 00:04:19 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:04:24 - Current stats for warrior_0719: 10 tweets, 0 threads...\n",
      "28-May-24 00:04:39 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:04:44 - Current stats for ChartingProdigy: 10 tweets, 0 threads...\n",
      "28-May-24 00:04:59 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:05:04 - Current stats for allstarcharts: 10 tweets, 0 threads...\n",
      "28-May-24 00:05:19 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:05:19 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:05:36 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:05:37 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:05:54 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:05:59 - Current stats for AdamMancini4: 10 tweets, 0 threads...\n",
      "28-May-24 00:06:14 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:06:14 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:06:31 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:06:32 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:06:49 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:06:50 - Empty page on https://nitter.privacydev.net\n",
      "$AAPL was mentioned 2 times in the last 3.13 minutes\n",
      "28-May-24 00:12:07 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:12:13 - Current stats for Mr_Derivatives: 10 tweets, 0 threads...\n",
      "28-May-24 00:12:28 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:12:32 - Current stats for warrior_0719: 10 tweets, 0 threads...\n",
      "28-May-24 00:12:47 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:12:52 - Current stats for ChartingProdigy: 10 tweets, 0 threads...\n",
      "28-May-24 00:13:07 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:13:12 - Current stats for allstarcharts: 10 tweets, 0 threads...\n",
      "28-May-24 00:13:27 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:13:28 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:13:45 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:13:46 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:14:03 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:14:08 - Current stats for AdamMancini4: 10 tweets, 0 threads...\n",
      "28-May-24 00:14:23 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:14:23 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:14:40 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:14:41 - Empty page on https://nitter.privacydev.net\n",
      "28-May-24 00:14:58 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "28-May-24 00:14:59 - Empty page on https://nitter.privacydev.net\n",
      "$AAPL was mentioned 2 times in the last 3.15 minutes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # List of Twitter account usernames to scrape\n",
    "    usernames = [\n",
    "        \"Mr_Derivatives\",\n",
    "        \"warrior_0719\",\n",
    "        \"ChartingProdigy\",\n",
    "        \"allstarcharts\",\n",
    "        \"yuriymatso\",\n",
    "        \"TriggerTrades\",\n",
    "        \"AdamMancini4\",\n",
    "        \"CordovaTrades\",\n",
    "        \"Barchart\",\n",
    "        \"RoyLMattox\"\n",
    "    ]\n",
    "    # Stock symbol to look for in tweets\n",
    "    stock_symbol = \"$AAPL\"\n",
    "    # Time interval between scrapes in minutes\n",
    "    interval = 5 # in minutes\n",
    "    \n",
    "    # Call the main function to start the scraping process\n",
    "    main(usernames, stock_symbol, interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
